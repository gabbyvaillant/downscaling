{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ad08e0-d13e-4527-8232-5ee98a6e2bef",
   "metadata": {},
   "source": [
    "# Preprocessing uWRF Dataset\n",
    "\n",
    "## Step 1:\n",
    "\n",
    "Retrieve uWRF data from BNL's remote servers.\n",
    "NOTE: Currently only working with the data for October 11th 2019\n",
    "## Step 2:\n",
    "Use the filter_vars function to filter the dataset down to the variables of interest:\n",
    "\n",
    "* T2 (Temperature 2m above surface)\n",
    "* U10 (U component of wind 10m above surface)\n",
    "* V10 (V component of wind 10m above surface)\n",
    "* PSFC (Pressure at the surface)\n",
    "\n",
    "\n",
    "## Step 3: \n",
    "Filter spatially to only include area covering Manhattan.\n",
    "\n",
    "## Step 4:\n",
    "Combine each day of data into a sequential format\n",
    "d02 = time: 29 (3 hourly)\n",
    "d03 = 85 (hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "759de5fd-db3f-439d-badc-5959140fecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import xarray as xarray\n",
    "import os\n",
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4dd174c7-bedf-4a2c-9d66-15e122303fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2:\n",
    "def filter_vars(input_dir, output_dir, variables):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Filter netCDF files down to contain variables of interest\n",
    "    \n",
    "    Args:\n",
    "    input_dir: directory on computer holding orignal netCDF files\n",
    "    output_dir: directory on computer where you want the filtered datasets to be stored\n",
    "    variables: list of variables to keep after filtering\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    Filtered datasets in the specified output_dir\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get a list of all files in the input directory\n",
    "    input_files = glob.glob(os.path.join(input_dir, '*'))  # Match all files\n",
    "    \n",
    "    #Loop through all the files in the input_dir\n",
    "    for file in input_files:\n",
    "        #Read and open the file\n",
    "        data = xr.open_dataset(file)\n",
    "\n",
    "        #Only keep the selected variables\n",
    "        data_filtered = data[variables]\n",
    "        \n",
    "        #Create the output file path\n",
    "        filename = os.path.basename(file)\n",
    "        output_file = os.path.join(output_dir, filename)\n",
    "\n",
    "        #Save the file to a new NetCDF file\n",
    "        data_filtered.to_netcdf(output_file)\n",
    "        \n",
    "        # Close the datasets\n",
    "        data.close()\n",
    "        data_filtered.close()\n",
    "\n",
    "\n",
    "    print('done filtering files')\n",
    "\n",
    "\n",
    "input_dir = '/Users/gabbyvaillant/Downloads/BNL/NYC_wrfout_20191011' \n",
    "output_dir = '/Users/gabbyvaillant/Downloads/BNL/uWRF-20191011-filtered'\n",
    "variables = ['T2', 'U10', 'V10', 'PSFC']\n",
    "\n",
    "#Uncomment to do filtering\n",
    "#filter_vars(input_dir, output_dir, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "402abcd3-aecc-4042-ad83-00a48e4aae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved to /Users/gabbyvaillant/Downloads/BNL/uwrf-sequential/uwrf_d02_20191011_seq\n"
     ]
    }
   ],
   "source": [
    "#STEP 3:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Taking all the uWRF files for 10/11/2019 and combining them into one file in sequential order.\n",
    "Edit this code to work for either domain 2 or domain 3.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Directory containing the stage 1 files:\n",
    "stage1_file_dir = '/Users/gabbyvaillant/Downloads/BNL/uWRF-20191011-filtered'\n",
    "output_file_path = '/Users/gabbyvaillant/Downloads/BNL/uwrf-sequential/uwrf_d02_20191011_seq'\n",
    "\n",
    "#output_file_path = '/Users/gabbyvaillant/Downloads/BNL/uwrf-sequential/uwrf_d03_20191011_seq.nc'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#List all files in the directory that match the naming format for domain 2\n",
    "nc_files = [os.path.join(stage1_file_dir, file) for file in os.listdir(stage1_file_dir)\n",
    "            if file.startswith('wrfout_d02_')]\n",
    "\n",
    "#Sort files in sequential order\n",
    "nc_files.sort()\n",
    "\n",
    "#Open all files as xarray datasets and combine them along the time dimension\n",
    "datasets = [xr.open_dataset(nc_file) for nc_file in nc_files]\n",
    "\n",
    "#Merge on time dimension\n",
    "combined_dataset = xr.concat(datasets, dim='Time')\n",
    "combined_dataset.to_netcdf(output_file_path)\n",
    "\n",
    "for ds in datasets:\n",
    "    ds.close()\n",
    "\n",
    "print(f'Combined dataset saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d58ff691-bf0a-4005-925c-287b7dc35ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset variables and dimensions:\n",
      "<xarray.Dataset> Size: 14MB\n",
      "Dimensions:  (Time: 85, south_north: 81, west_east: 84)\n",
      "Coordinates:\n",
      "    XLAT     (Time, south_north, west_east) float32 2MB ...\n",
      "    XLONG    (Time, south_north, west_east) float32 2MB ...\n",
      "    XTIME    (Time) datetime64[ns] 680B ...\n",
      "Dimensions without coordinates: Time, south_north, west_east\n",
      "Data variables:\n",
      "    T2       (Time, south_north, west_east) float32 2MB ...\n",
      "    U10      (Time, south_north, west_east) float32 2MB ...\n",
      "    V10      (Time, south_north, west_east) float32 2MB ...\n",
      "    PSFC     (Time, south_north, west_east) float32 2MB ...\n",
      "Attributes: (12/119)\n",
      "    TITLE:                            OUTPUT FROM WRF V3.9.1.1 MODEL\n",
      "    START_DATE:                      2019-10-11_00:00:00\n",
      "    SIMULATION_START_DATE:           2019-10-11_00:00:00\n",
      "    WEST-EAST_GRID_DIMENSION:        85\n",
      "    SOUTH-NORTH_GRID_DIMENSION:      82\n",
      "    BOTTOM-TOP_GRID_DIMENSION:       51\n",
      "    ...                              ...\n",
      "    ISLAKE:                          -1\n",
      "    ISICE:                           15\n",
      "    ISURBAN:                         13\n",
      "    ISOILWATER:                      14\n",
      "    HYBRID_OPT:                      -1\n",
      "    ETAC:                            0.0\n",
      "Latitude bounds: 40.57384924257281 to 40.90231421796557\n",
      "Longitude bounds: -74.0481110602903 to -73.84627819243957\n",
      "Dataset variables and dimensions:\n",
      "<xarray.Dataset> Size: 10MB\n",
      "Dimensions:  (Time: 29, south_north: 120, west_east: 120)\n",
      "Coordinates:\n",
      "    XLAT     (Time, south_north, west_east) float32 2MB ...\n",
      "    XLONG    (Time, south_north, west_east) float32 2MB ...\n",
      "    XTIME    (Time) datetime64[ns] 232B ...\n",
      "Dimensions without coordinates: Time, south_north, west_east\n",
      "Data variables:\n",
      "    T2       (Time, south_north, west_east) float32 2MB ...\n",
      "    U10      (Time, south_north, west_east) float32 2MB ...\n",
      "    V10      (Time, south_north, west_east) float32 2MB ...\n",
      "    PSFC     (Time, south_north, west_east) float32 2MB ...\n",
      "Attributes: (12/119)\n",
      "    TITLE:                            OUTPUT FROM WRF V3.9.1.1 MODEL\n",
      "    START_DATE:                      2019-10-11_00:00:00\n",
      "    SIMULATION_START_DATE:           2019-10-11_00:00:00\n",
      "    WEST-EAST_GRID_DIMENSION:        121\n",
      "    SOUTH-NORTH_GRID_DIMENSION:      121\n",
      "    BOTTOM-TOP_GRID_DIMENSION:       51\n",
      "    ...                              ...\n",
      "    ISLAKE:                          -1\n",
      "    ISICE:                           15\n",
      "    ISURBAN:                         13\n",
      "    ISOILWATER:                      14\n",
      "    HYBRID_OPT:                      -1\n",
      "    ETAC:                            0.0\n",
      "Latitude bounds: 40.57384924257281 to 40.90231421796557\n",
      "Longitude bounds: -74.0481110602903 to -73.84627819243957\n"
     ]
    }
   ],
   "source": [
    "#STEP 4:\n",
    "def stage_1_filtering(file_path, output_directory):\n",
    "\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    \n",
    "    print(\"Dataset variables and dimensions:\")\n",
    "    print(ds)\n",
    "    \n",
    "    lat_var = 'XLAT'\n",
    "    lon_var = 'XLONG'\n",
    "    \n",
    "    if lat_var not in ds.variables or lon_var not in ds.variables:\n",
    "        #Print available variables if defaults are not found\n",
    "        print(f\"Available variables: {list(ds.variables)}\")\n",
    "        raise ValueError(f\"Dataset does not contain '{lat_var}' or '{lon_var}' variables\")\n",
    "    \n",
    "    lat = ds[lat_var].values\n",
    "    lon = ds[lon_var].values\n",
    "    \n",
    "    # Specified bounds of the dataset\n",
    "    min_lat = 40.57384924257281\n",
    "    max_lat = 40.90231421796557\n",
    "    min_lon = -74.0481110602903\n",
    "    max_lon = -73.84627819243957\n",
    "    \n",
    "    print(f\"Latitude bounds: {min_lat} to {max_lat}\")\n",
    "    print(f\"Longitude bounds: {min_lon} to {max_lon}\")\n",
    "    \n",
    "    #Filter the data based on the lat and lon bounds\n",
    "    filtered_data = ds.where(\n",
    "        (ds[lat_var] >= min_lat) & (ds[lat_var] <= max_lat) &\n",
    "        (ds[lon_var] >= min_lon) & (ds[lon_var] <= max_lon), drop=True\n",
    "    )\n",
    "\n",
    "    #Construct the output file path\n",
    "    output_file_path = os.path.join(output_directory, os.path.basename(file_path))\n",
    "    \n",
    "    filtered_data.to_netcdf(output_file_path)\n",
    "    \n",
    "    ds.close()\n",
    "\n",
    "#Define directories\n",
    "input_directory = '/Users/gabbyvaillant/Downloads/BNL/uwrf-sequential/'\n",
    "output_directory = '/Users/gabbyvaillant/Downloads/BNL/uWRF-final-files/'\n",
    "\n",
    "#Make sure the output directory exists or create it if not\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "#Loop through all files in the input directory and apply the filtering function\n",
    "for filename in os.listdir(input_directory):\n",
    "    file_path = os.path.join(input_directory, filename)\n",
    "    if filename.endswith('.nc'):\n",
    "        stage_1_filtering(file_path, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
